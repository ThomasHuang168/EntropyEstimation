{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_size_Mine = 3\n",
    "class Mine(nn.Module):\n",
    "    def __init__(self, input_size=Input_size_Mine, hidden_size=100):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)\n",
    "        nn.init.normal_(self.fc1.weight,std=0.02)\n",
    "        nn.init.constant_(self.fc1.bias, 0)\n",
    "        nn.init.normal_(self.fc2.weight,std=0.02)\n",
    "        nn.init.constant_(self.fc2.bias, 0)\n",
    "        nn.init.normal_(self.fc3.weight,std=0.02)\n",
    "        nn.init.constant_(self.fc3.bias, 0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = F.elu(self.fc1(input))\n",
    "        output = F.elu(self.fc2(output))\n",
    "        output = self.fc3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(joint, marginal, mine_net):\n",
    "    t = mine_net(joint)\n",
    "    et = torch.exp(mine_net(marginal))\n",
    "    mi_lb = torch.mean(t) - torch.log(torch.mean(et))\n",
    "    return mi_lb, t, et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_mine(batch, mine_net, mine_net_optim,  ma_et, ma_rate=0.01):\n",
    "    # batch is a tuple of (joint, marginal)\n",
    "    joint , marginal = batch\n",
    "    joint = torch.autograd.Variable(torch.FloatTensor(joint))\n",
    "    marginal = torch.autograd.Variable(torch.FloatTensor(marginal))\n",
    "    mi_lb , t, et = mutual_information(joint, marginal, mine_net)\n",
    "    ma_et = (1-ma_rate)*ma_et + ma_rate*torch.mean(et)\n",
    "    \n",
    "    # unbiasing use moving average\n",
    "    loss = -(torch.mean(t) - (1/ma_et.mean()).detach()*torch.mean(et))\n",
    "    # use biased estimator\n",
    "#     loss = - mi_lb\n",
    "    \n",
    "    mine_net_optim.zero_grad()\n",
    "    autograd.backward(loss)\n",
    "    mine_net_optim.step()\n",
    "    return mi_lb, ma_et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(data, batch_size=100, sample_mode='joint'):\n",
    "    if sample_mode == 'joint':\n",
    "        index = np.random.choice(range(data.shape[0]), size=batch_size, replace=False)\n",
    "        batch = data[index]\n",
    "    else:\n",
    "        joint_index = np.random.choice(range(data.shape[0]), size=batch_size, replace=False)\n",
    "        marginal_index = np.random.choice(range(data.shape[0]), size=batch_size, replace=False)\n",
    "        batch = np.concatenate([data[joint_index][:,0].reshape(-1,1),\n",
    "                                         data[marginal_index][:,1].reshape(-1,1)],\n",
    "                                       axis=1)\n",
    "        for i in range(2, Input_size_Mine):\n",
    "            marginal_index = np.random.choice(range(data.shape[0]), size=batch_size, replace=False)\n",
    "            batch = np.append(batch, data[marginal_index][:,i].reshape(-1,1), axis=1)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, mine_net,mine_net_optim, batch_size=100, iter_num=int(5e+3), log_freq=int(1e+3), verbose=True):\n",
    "    # data is x or y\n",
    "    result = list()\n",
    "    ma_et = 1.\n",
    "    for i in range(iter_num):\n",
    "        batch = sample_batch(data,batch_size=batch_size)        , sample_batch(data,batch_size=batch_size,sample_mode='marginal')\n",
    "        mi_lb, ma_et = learn_mine(batch, mine_net, mine_net_optim, ma_et)\n",
    "        result.append(mi_lb.detach().cpu().numpy())\n",
    "        if verbose and (i+1)%(log_freq)==0:\n",
    "            print(result[-1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ma(a, window_size=100):\n",
    "    return [np.mean(a[i:i+window_size]) for i in range(0,len(a)-window_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.stats import randint\n",
    "import DiscreteCondEnt as DC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linReg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varEntropy(y):\n",
    "    return np.log(np.var(y)*3.14159*2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def MSEscorer(clf, X, y):\n",
    "    y_est = clf.predict(X)\n",
    "    return np.log(mean_squared_error(y, y_est)*3.14159*2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVFold = 3\n",
    "MINE2 = []\n",
    "LinReg2 = []\n",
    "GT2 = []\n",
    "#COV2 = []\n",
    "#for i in range(1, 16):\n",
    "#    cov = 1 - 0.1**\n",
    "#    COV2.append(cov)i\n",
    "COV2 = np.linspace(0, 0.9, 5)\n",
    "for cov in COV2:\n",
    "    Gaussian_cov = [[1,0,cov],[0,1,cov],[cov,cov,1]]\n",
    "    x = np.transpose(np.random.multivariate_normal( mean=[0,0,0],\n",
    "                                  cov=Gaussian_cov,\n",
    "                                 size = 300))\n",
    "    DE = DC.computeEnt(x, linReg, MSEscorer, varEntropy, CVFold)\n",
    "    MI = DE[1,0] + DE[0,0] - DE[0,1] - DE[1,1]\n",
    "    MI = MI/2\n",
    "    LinReg2.append(MI)\n",
    "    \n",
    "    #groundTruth = -0.5*np.log(1-cov*cov)\n",
    "    groundTruth = -0.5*np.log(np.linalg.det(np.array(Gaussian_cov)))\n",
    "    GT2.append(groundTruth)\n",
    "    \n",
    "    #MINE\n",
    "    mine_net = Mine()\n",
    "    mine_net_optim = optim.Adam(mine_net.parameters(), lr=1e-3)\n",
    "    result = train(np.transpose(x),mine_net,mine_net_optim)\n",
    "    result_ma = ma(result)\n",
    "    MINE2.append(result_ma[-1])\n",
    "    #MINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(COV2, MINE2, c='b', label='MINE')\n",
    "ax.scatter(COV2, LinReg2, c='r', label='Regressor')\n",
    "ax.scatter(COV2, GT2, c='g', label='Ground Truth')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots()\n",
    "COV22 = np.log(np.ones(len(COV2)) - COV2)\n",
    "ax2.scatter(COV22, MINE2, c='b', label='MINE')\n",
    "ax2.scatter(COV22, LinReg2, c='r', label='Regressor')\n",
    "ax2.scatter(COV22, GT2, c='g', label='Ground Truth')\n",
    "\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
